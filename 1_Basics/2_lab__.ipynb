{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc636d12",
   "metadata": {},
   "source": [
    "# Welcome to the Agentic part of this guide\n",
    "## Before we start discussing, let's get a recap of what we did last time: -\n",
    "1. We learnt what Agents are, where they are used and difference between them and normal generative AI.\n",
    "2. We learnt what APIs are and coded OpenAI's API in *python* to access ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724d7ad",
   "metadata": {},
   "source": [
    "- Now, if we put our logic in coding and theory we discussed last time: -\n",
    "- We find out that Agents are basically automated AIs, now before coding, let's take a look at an example that doesn't require coding\n",
    "- Go to this website called [n8n](https://n8n.io/), where we can build agents in a diagramtic/flowchart format.\n",
    "- This website requires a subscription, but you have limited tries to build an agent.\n",
    "- Try it for your self, put your logic in and learn how automation works, where if one task is completed, many other tasks start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d39c76",
   "metadata": {},
   "source": [
    "## **Automation** is when tasks are done by machines or software without needing people to do them step by step.\n",
    "- Example: Instead of you sending an email to *100 people one by one*, a *script* or tool can send them all automatically.\n",
    "- We can code automations in *python* and use them with the API we learnt, that creates an AI Agent, and your first step towards learning the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ef02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7a0b7",
   "metadata": {},
   "source": [
    "## Now, these imports are necessary for AI agents to do tasks for you, agentic tasks in an automated manner: -\n",
    "1. `openai` - access to openai api\n",
    "2. `pypdf` - from it we import `PdfReader` for access to reading pdfs\n",
    "3. `dotenv` - loading environment variables\n",
    "4. `gradio` - giving this app a GUI (Graphical User Interface)\n",
    "5. `os` - for accessing files on your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488aef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"samples/sample1.pdf\")\n",
    "chapter = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        chapter += text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211598cf",
   "metadata": {},
   "source": [
    "- `reader = PdfReader(\"samples/sample1.pdf\")` - load PDF file into reader object\n",
    "- `chapter = \"\"` - create an empty string to store extracted text\n",
    "- `for page in reader.pages:` - iterates over all pages in PDF\n",
    "- `text = page.extract_text()` - gets text content of the current page\n",
    "- `if text: chapter_name += text` - adds the page text to `chapter` if text exists\n",
    "### After loop ends, the entire text of the pdf is intialized into the `chapter` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da78afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"samples/sample1.pdf\", \"rb\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "name = \"Structured Query Language (SQL)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd0d2f",
   "metadata": {},
   "source": [
    "- `with open(\"samples/sample1.pdf\", \"rb\", encoding=\"utf-8\") as f` \n",
    "  - opens the pdf file in read binary (rb) mode, no need to know about read binary mode right now.\n",
    "  - Uses utf-8 encoding.\n",
    "  - `with` ensures file is closed after use.\n",
    "  - `f` is file object, stored in it.\n",
    "- `summary = f.read( )` - reads the entire content of the file and stores it in variable summary.\n",
    "- `name = \"Structured Query Language\"` - variable assigned for the file's topic and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=f\"\"\"You are every student's favorite teacher who specializes in teaching grade 12 in India, teaching them chapter - {name}. \\n\n",
    "                  You are answering questions on {name}'s topic, particularly questions related to {name}'s syntax and content of the chapter. \\n\n",
    "                  Your responsibility is to represent a teacher, who is good in programming as well as teaching students. But, give feedback to \n",
    "                  students as faithfully as possible. Be helpful and engaging, as if talking to a future topper or a potiential breakthrough maker\n",
    "                  in the tech industry. If you don't know the answer say so.\"\"\"\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## Chapter name\\n{name}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as that favorite teacher.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e1786",
   "metadata": {},
   "source": [
    "- What we are doing is making some really good prompts that help that AI in really understanding the context of the questions and how they have to be answered.\n",
    "- We are assigning those really good prompts into variable `system_prompt`, and adding information to it by doing `+=` to the `system_prompt` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt #intialize the final content of the variable\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e72e3",
   "metadata": {},
   "source": [
    "- What we are doing is now intializing the OpenAI API for access to ChatGPT's `gpt-4o-mini` model, if open this and learn - [API_Guide](1_lab_startHere.ipynb), for the better of you.\n",
    "- We are giving the the `\"role\": \"system\"` for custom instructions which we assigned to earlier `system_prompt` variable, which is a good practice for any AI assistant, whether it is ChatGPT, Gemini, Grok, DeepSeek; anything needs instructions for better understanding of context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
