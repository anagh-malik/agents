{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc636d12",
   "metadata": {},
   "source": [
    "# Welcome to the Agentic part of this guide\n",
    "## Before we start discussing, let's get a recap of what we did last time: -\n",
    "1. We learnt what Agents are, where they are used and difference between them and normal generative AI.\n",
    "2. We learnt what APIs are and coded OpenAI's API in *python* to access ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724d7ad",
   "metadata": {},
   "source": [
    "- Now, if we put our logic in coding and theory we discussed last time: -\n",
    "- We find out that Agents are basically automated AIs, now before coding, let's take a look at an example that doesn't require coding\n",
    "- Go to this website called [n8n](https://n8n.io/), where we can build agents in a diagramtic/flowchart format.\n",
    "- This website requires a subscription, but you have limited tries to build an agent.\n",
    "- Try it for your self, put your logic in and learn how automation works, where if one task is completed, many other tasks start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d39c76",
   "metadata": {},
   "source": [
    "## **Automation** is when tasks are done by machines or software without needing people to do them step by step.\n",
    "- Example: Instead of you sending an email to *100 people one by one*, a *script* or tool can send them all automatically.\n",
    "- We can code automations in *python* and use them with the API we learnt, that creates an AI Agent, and your first step towards learning the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ef02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7a0b7",
   "metadata": {},
   "source": [
    "## Now, these imports are necessary for AI agents to do tasks for you, agentic tasks in an automated manner: -\n",
    "1. `openai` - access to openai api\n",
    "2. `pypdf` - from it we import `PdfReader` for access to reading pdfs\n",
    "3. `dotenv` - loading environment variables\n",
    "4. `gradio` - giving this app a GUI (Graphical User Interface)\n",
    "5. `os` - for accessing files on your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488aef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"samples/sample1.pdf\")\n",
    "chapter = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        chapter += text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211598cf",
   "metadata": {},
   "source": [
    "- `reader = PdfReader(\"samples/sample1.pdf\")` - load PDF file into reader object\n",
    "- `chapter = \"\"` - create an empty string to store extracted text\n",
    "- `for page in reader.pages:` - iterates over all pages in PDF\n",
    "- `text = page.extract_text()` - gets text content of the current page\n",
    "- `if text: chapter_name += text` - adds the page text to `chapter` if text exists\n",
    "### After loop ends, the entire text of the pdf is intialized into the `chapter` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da78afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"samples/sample1.pdf\", \"rb\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "name = \"Structured Query Language (SQL)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd0d2f",
   "metadata": {},
   "source": [
    "- `with open(\"samples/sample1.pdf\", \"rb\", encoding=\"utf-8\") as f` \n",
    "  - opens the pdf file in read binary (rb) mode, no need to know about read binary mode right now.\n",
    "  - Uses utf-8 encoding.\n",
    "  - `with` ensures file is closed after use.\n",
    "  - `f` is file object, stored in it.\n",
    "- `summary = f.read( )` - reads the entire content of the file and stores it in variable summary.\n",
    "- `name = \"Structured Query Language\"` - variable assigned for the file's topic and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=f\"\"\"You are every student's favorite teacher who specializes in teaching grade 12 in India, teaching them chapter - {name}. \\n\n",
    "                  You are answering questions on {name}'s topic, particularly questions related to {name}'s syntax and content of the chapter. \\n\n",
    "                  Your responsibility is to represent a teacher, who is good in programming as well as teaching students. But, give feedback to \n",
    "                  students as faithfully as possible. Be helpful and engaging, as if talking to a future topper or a potiential breakthrough maker\n",
    "                  in the tech industry. If you don't know the answer say so.\"\"\"\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## Chapter\\n{chapter}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as that favorite teacher.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e1786",
   "metadata": {},
   "source": [
    "- What we are doing is making some really good prompts that help that AI in really understanding the context of the questions and how they have to be answered.\n",
    "- We are assigning those really good prompts into variable `system_prompt`, and adding information to it by doing `+=` to the `system_prompt` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt #intialize the final content of the variable\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e72e3",
   "metadata": {},
   "source": [
    "- What we are doing is now intializing the OpenAI API for access to ChatGPT's `gpt-4o-mini` model, if open this and learn - [API_Guide](1_lab_startHere.ipynb), for the better of you.\n",
    "- We are giving the the `\"role\": \"system\"` for custom instructions which we assigned to earlier `system_prompt` variable, which is a good practice for any AI assistant, whether it is ChatGPT, Gemini, Grok, DeepSeek; anything needs instructions for better understanding of context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d6f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n",
    "eval_sys_prompt = f\"\"\"You are an evaluator that decides whether a response to a question is acceptable. \\n\n",
    "                      You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\n\n",
    "                      The Agent is playing the role of a teacher who is every student's favorite and is answering questions based on the topic {name} on a website. \\n\n",
    "                      The Agent has been instructed to be helpful and engaging, as if talking to a future topper or a potiential breakthrough maker in the tech industry. \\n\n",
    "                      The Agent has been provided with context on the chapter {name} of class XII in form of a PDF.\"\"\"\n",
    "eval_sys_prompt += f\"\\n\\n##Summary:\\n{summary}\\n\\n## Chapter:\\n{chapter}\\n\\n\"\n",
    "eval_sys_prompt += f\"With this context, please evaluate the latest response, replying whether the solution is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc922fa",
   "metadata": {},
   "source": [
    "- We have used the `pydantic` library and imported the `BaseModel`.\n",
    "- Then we have defined a class `Evaluation` and given it the object, the model that we are using for evaluation, that we imported.\n",
    "- Fields of `class`: -\n",
    "  - `is_acceptable: bool` - Only accepts boolean values, which are either true or false.\n",
    "  - `feedback: str` - Only accepts the feedback as a string text.\n",
    "- `eval_sys_prompts` - given for greater context on how evaluation should work and reply be judged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57856e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35706d4",
   "metadata": {},
   "source": [
    "- The above provides the information the evaluator AI needs.\n",
    "- The information is then grouped into variables, `+=` adds info/data to the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "# This uses google's AI model gemini for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fdf823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    messages = [{\"role\": \"system\", \"content\": eval_sys_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46f2cc",
   "metadata": {},
   "source": [
    "- We have used gemini's model - `gemini-2.0-flash`, giving it the response format that we made earlier and stored as `class Evaluation(BaseModel)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"What is the full syntax of SQL?\"}]\n",
    "response = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content\n",
    "reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3041af",
   "metadata": {},
   "source": [
    "- We have again used `gpt-4o-mini` of OpenAI for the question to be sent to the model and response to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61816b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(reply, \"What is the full syntax of SQL?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYour just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9fe813",
   "metadata": {},
   "source": [
    "- We have now made a function that if something about the reply is not accepted, it will show to the AI what was wrong stored in the `updated_system_prompt` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29261c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"syntax\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be student friendly - \\\n",
    "                                  it is mandatory that you respond only and entirely in a student-friendly language.\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6552baf",
   "metadata": {},
   "source": [
    "- We have created a function to handle replies.\n",
    "- With a criterion that if `\"syntax\"` is in the question statment asked by the student, then change the system_prompt for model to reply to.\n",
    "- Then we have added an `if` statement, that if `evaluation` is acceptable - then print the output that the reply has passed.\n",
    "- Or else, the output will be print that the reply has failed with corresponding feedback with the `rerun( )` function taking place if this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198a52f",
   "metadata": {},
   "source": [
    "- We have made the interface in the above line using gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c057714",
   "metadata": {},
   "source": [
    "# Congrats, you have now just made a PDF analyst AI agent, which can answer any questions on SQL, the chapter of grade 12 NCERT Computer Science (book maker in India).\n",
    "- Based upon the code I give you a situation.\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"2_multiTasks.png\" style=\"display: block;\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <h1>Smart PDF Q-A Challenge</h1>\n",
    "            <p>Goal: Build a backend flow that reads a PDF, answers a user question using the OpenAI API, then evaluates that answer using the Gemini evaluation endpoint.</p>\n",
    "            <h2>Overview</h2>\n",
    "            <ul>\n",
    "                <li>Use PyPDF to extract text from the PDF.\n",
    "                <li>Send the extracted text (or a relevant excerpt) + user question to OpenAI API to generate a student-friendly answer.\n",
    "                <li>Send the OpenAI answer, original question, and a short source excerpt to the Gemini evaluation endpoint (via its URL) to get a correctness/coverage critique.\n",
    "                <li>Return both the answer and Gemini’s evaluation (printed output).\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
